{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark for Reading and Datamining PDB Structures with mmtf-pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from mmtfPyspark.io import mmtfReader\n",
    "from mmtfPyspark.filters import ContainsGroup\n",
    "from mmtfPyspark.utils import ColumnarStructure\n",
    "from mmtfPyspark.interactions import InteractionExtractorPd\n",
    "\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the benchmark\n",
    "Set the path to the MMTF Hadoop Sequence file. Here we retrieve the value of the environment variable MMTF_FULL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "path = mmtfReader.get_mmtf_full_path()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify a list with the number of cores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "cores = [4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create results directory\n",
    "results_dir = '../results'\n",
    "if not os.path.exists(results_dir):\n",
    "    os.makedirs(results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure Benchmark\n",
    "This benchmark read structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def structure(path, num_cores):\n",
    "    spark = SparkSession.builder.master(\"local[\" + str(num_cores) + \"]\").appName(\"Benchmark3\").getOrCreate()\n",
    "    structures = mmtfReader.read_sequence_file(path, first_model=True)                \n",
    "    count = structures.count()\n",
    "\n",
    "    spark.stop()\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_s = pd.DataFrame(columns=('cores', 'structures'))\n",
    "\n",
    "for num_cores in cores:\n",
    "    start = time.time()\n",
    "    count = structure(path, num_cores)\n",
    "    end = time.time()\n",
    "    print('structures, cores:', num_cores, 'time:', end-start, 'seconds')\n",
    "    df_s = df_s.append([{'cores':num_cores, 'structures': end-start, 'count': count}], ignore_index=True, sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_s.to_csv(os.path.join(results_dir, 'structures.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "df_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.master(\"local[4]\").appName(\"Benchmark3\").getOrCreate()\n",
    "#structures = mmtfReader.read_sequence_file(path, first_model=True)\n",
    "structures = mmtfReader.download_full_mmtf_files(['4HHB'])\n",
    "#structures = structures.filter(lambda s: s[0] == '4HHB')\n",
    "dfs = structures.values().first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# df = pd.DataFrame({'chain_name': dfs.chain_names,\n",
    "#                                     'chain_id': dfs.chain_ids,\n",
    "#                                     'group_number': dfs.group_numbers,\n",
    "#                                     'group_name': dfs.group_names,\n",
    "#                                     'atom_name': dfs.atom_names,\n",
    "#                                     'altloc': dfs.alt_loc_list,\n",
    "#                                     'x': dfs.x_coord_list,\n",
    "#                                     'y': dfs.y_coord_list,\n",
    "#                                     'z': dfs.z_coord_list,\n",
    "#                                     'o': dfs.occupancy_list,\n",
    "#                                     'b': dfs.b_factor_list,\n",
    "#                                     'element': dfs.elements,\n",
    "#                                     'polymer:': dfs.polymer\n",
    "#                                     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame({'z': dfs.z_coord_list})\n",
    "#dfs.num_atoms\n",
    "#dfs.occupancy_list\n",
    "dfs.z_coord_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['chain_name'] = df['chain_name'].astype('category')\n",
    "df['group_name'] = df['group_name'].astype('category')\n",
    "df['atom_name'] = df['atom_name'].astype('category')\n",
    "df['altloc'] = df['altloc'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
